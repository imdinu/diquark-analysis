{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "\n",
    "import diquark.constants as const\n",
    "from diquark.plotting import make_histogram, make_histogram_with_double_gaussian_fit\n",
    "from diquark.helpers import mass_score_cut\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tfkl = tf.keras.layers\n",
    "tfk = tf.keras\n",
    "\n",
    "if os.getcwd().split(\"/\")[-1] == \"notebooks\":\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the latest workdir\n",
    "workdir = sorted(os.listdir(\"models\"))[-1]\n",
    "workdir = os.path.join(\"models\", workdir)\n",
    "\n",
    "# manually set the workdir\n",
    "# workdir = \"models/run_20240201131751\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(f\"{workdir}/train.parquet\")\n",
    "df_test = pd.read_parquet(f\"{workdir}/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df_test[[\"Truth\", \"inv_mass\"]].reset_index(drop=True)\n",
    "train_df = df_train[[\"Truth\", \"inv_mass\"]].reset_index(drop=True)\n",
    "\n",
    "m6j_test = joblib.load(f\"{workdir}/m6j_test.data.joblib\")\n",
    "m6j_train = joblib.load(f\"{workdir}/m6j_train.data.joblib\")\n",
    "\n",
    "data_npz = np.load(f\"{workdir}/data.npz\")\n",
    "x_train, y_train, x_test, y_test = (\n",
    "    data_npz[\"x_train\"],\n",
    "    data_npz[\"y_train\"],\n",
    "    data_npz[\"x_test\"],\n",
    "    data_npz[\"y_test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tfk.models.load_model(f\"{workdir}/model.keras\")\n",
    "rf_clf = joblib.load(f\"{workdir}/rfc.joblib\")\n",
    "gb_clf = joblib.load(f\"{workdir}/gbc.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nn = model.predict(x_test)\n",
    "y_pred_gb = gb_clf.predict_proba(x_test)[:, 1]\n",
    "y_pred_rf = rf_clf.predict_proba(x_test)[:, 1]\n",
    "\n",
    "sample_weights = [const.CROSS_SECTION_ATLAS_130_85[label] for label in test_df[\"Truth\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the first model\n",
    "# precision_nn, recall_nn, thresholds_nn = precision_recall_curve(y_test, y_pred_nn)\n",
    "precision_nn, recall_nn, thresholds_nn = precision_recall_curve(\n",
    "    y_test, y_pred_nn, sample_weight=sample_weights\n",
    ")\n",
    "pr_auc_nn = auc(recall_nn, precision_nn)\n",
    "\n",
    "# For the Gradient Boosting model\n",
    "# precision_gb, recall_gb, thresholds_gb = precision_recall_curve(y_test, y_pred_gb)\n",
    "precision_gb, recall_gb, thresholds_gb = precision_recall_curve(\n",
    "    y_test, y_pred_gb, sample_weight=sample_weights\n",
    ")\n",
    "pr_auc_gb = auc(recall_gb, precision_gb)\n",
    "\n",
    "# For the Random Forest model\n",
    "# precision_rf, recall_rf, thresholds_rf = precision_recall_curve(y_test, y_pred_rf)\n",
    "precision_rf, recall_rf, thresholds_rf = precision_recall_curve(\n",
    "    y_test, y_pred_rf, sample_weight=sample_weights\n",
    ")\n",
    "pr_auc_rf = auc(recall_rf, precision_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=recall_gb,\n",
    "        y=precision_gb,\n",
    "        customdata=thresholds_gb,\n",
    "        hovertemplate=\"Threshold=%{customdata}<br>Recall=%{x}<br>Precision=%{y}\",\n",
    "        mode=\"lines\",\n",
    "        name=f\"BDT - AUC={pr_auc_gb:.3f}\",\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=recall_rf,\n",
    "        y=precision_rf,\n",
    "        customdata=thresholds_rf,\n",
    "        hovertemplate=\"Threshold=%{customdata}<br>Recall=%{x}<br>Precision=%{y}\",\n",
    "        mode=\"lines\",\n",
    "        name=f\"RF - AUC={pr_auc_rf:.3f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=recall_nn,\n",
    "        y=precision_nn,\n",
    "        customdata=thresholds_nn,\n",
    "        hovertemplate=\"Threshold=%{customdata}<br>Recall=%{x}<br>Precision=%{y}\",\n",
    "        mode=\"lines\",\n",
    "        name=f\"NN - AUC={pr_auc_nn:.3f}\",\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"Cross-Section Weighted Precision-Recall Curves\",\n",
    "    xaxis_title=\"Recall\",\n",
    "    yaxis_title=\"Precision\",\n",
    "    width=1200 * (2 / 3),\n",
    "    height=800 * (2 / 3),\n",
    "    xaxis_range=[0.1, 1],\n",
    ")\n",
    "fig.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "fig.write_image(f\"{workdir}/plots/PR-curve-w.pdf\")\n",
    "fig.write_image(f\"{workdir}/plots/PR-curve-w.jpg\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_test_rf = {}\n",
    "for key in test_df[\"Truth\"].unique():\n",
    "    scores_test_rf[key] = y_pred_rf.flatten()[test_df[test_df[\"Truth\"] == key].index]\n",
    "\n",
    "scores_test_gb = {}\n",
    "for key in test_df[\"Truth\"].unique():\n",
    "    scores_test_gb[key] = y_pred_gb.flatten()[test_df[test_df[\"Truth\"] == key].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_histogram(scores_test_rf, 50, clip_top_prc=100, clip_bottom_prc=0, cross=None)\n",
    "fig.update_layout(\n",
    "    title_text=\"Data Sample Content by Model Output Cut\",\n",
    "    barmode=\"stack\",\n",
    "    yaxis_type=\"log\",\n",
    "    xaxis_title=\"RF Output\",\n",
    "    yaxis_title=\"Probability Density\",\n",
    "    width=1600 * (5 / 6),\n",
    "    height=900 * (5 / 6),\n",
    ")\n",
    "fig.write_image(f\"{workdir}/plots/RF-output.pdf\")\n",
    "fig.write_image(f\"{workdir}/plots/RF-output.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_histogram(scores_test_gb, 50, clip_top_prc=100, clip_bottom_prc=0, cross=None)\n",
    "fig.update_layout(\n",
    "    title_text=\"Data Sample Content by Model Output Cut\",\n",
    "    barmode=\"stack\",\n",
    "    yaxis_type=\"log\",\n",
    "    xaxis_title=\"GB Output\",\n",
    "    yaxis_title=\"Probability Density\",\n",
    "    width=1600 * (5 / 6),\n",
    "    height=900 * (5 / 6),\n",
    ")\n",
    "fig.write_image(f\"{workdir}/plots/GB-output.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from Random Forest\n",
    "rf_importance = rf_clf.feature_importances_\n",
    "gb_importance = gb_clf.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = df_train.drop([\"target\", \"Truth\", \"inv_mass\"], axis=1).columns\n",
    "\n",
    "# Create a grouped bar chart\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add bars for Random Forest\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=feature_names,\n",
    "        y=rf_importance,\n",
    "        name=\"Random Forest\",\n",
    "        offsetgroup=1,\n",
    "        marker=dict(color=\"#E4D91B\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add bars for Random Forest\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=feature_names,\n",
    "        y=gb_importance,\n",
    "        name=\"Gradient Boosting\",\n",
    "        offsetgroup=2,\n",
    "        marker=dict(color=\"#D91BE4\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Feature Importances for Random Forest\",\n",
    "    xaxis_title=\"Features\",\n",
    "    yaxis_title=\"Importance Value\",\n",
    "    # legend_title='Classifier',\n",
    "    xaxis=dict(tickangle=45),\n",
    "    barmode=\"group\",\n",
    "    width=1200,\n",
    ")\n",
    "fig.write_image(f\"{workdir}/plots/feature_importances.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top 10 features by importance\n",
    "print(\"Top 10 features by importance\")\n",
    "print(\"Random Forest\")\n",
    "print(feature_names[np.argsort(rf_importance)[::-1][:10]])\n",
    "print(\"Gradient Boosting\")\n",
    "print(feature_names[np.argsort(gb_importance)[::-1][:10]])\n",
    "\n",
    "# vertical bar chart for random forest top 10\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        y=feature_names[np.argsort(rf_importance)[::-1][:10]][::-1],\n",
    "        x=rf_importance[np.argsort(rf_importance)[::-1][:10]][::-1],\n",
    "        name=\"Random Forest\",\n",
    "        offsetgroup=1,\n",
    "        marker=dict(color=\"#E4D91B\"),\n",
    "        orientation=\"h\",\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"Top 10 Features by Importance for Random Forest\",\n",
    "    xaxis_title=\"Features\",\n",
    "    yaxis_title=\"Importance Value\",\n",
    "    # legend_title='Classifier',\n",
    "    xaxis=dict(tickangle=45),\n",
    "    barmode=\"group\",\n",
    "    width=600,\n",
    "    height=800,\n",
    ")\n",
    "fig.write_image(f\"{workdir}/plots/top10_RF.pdf\")\n",
    "fig.write_image(f\"{workdir}/plots/top10_RF.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_histogram_with_double_gaussian_fit(\n",
    "    mass_score_cut(m6j_test, scores_test_rf, 0.99, prc=True),\n",
    "    20,\n",
    "    clip_top_prc=100,\n",
    "    cross=const.CROSS_SECTION_ATLAS_130_85,\n",
    ")\n",
    "# fig = make_histogram(mass_score_cut(m6j_test, scores_test_rf, 0.95, prc=False), 20, clip_top_prc=100)\n",
    "fig.update_layout(\n",
    "    title=\"6-jet Mass\",\n",
    "    xaxis_title=\"Invariant Mass [GeV]\",\n",
    "    yaxis_title_text=\"count x sigma\",\n",
    "    # yaxis_type=\"log\",\n",
    "    barmode=\"stack\",\n",
    "    bargap=0,\n",
    "    width=1600 * (2 / 3),\n",
    "    height=800 * (2 / 3),\n",
    ")\n",
    "fig.update_legends(\n",
    "    title_text=\"\",\n",
    "    itemsizing=\"constant\",\n",
    "    yanchor=\"top\",\n",
    "    y=0.99,\n",
    "    xanchor=\"left\",\n",
    "    x=0.01,\n",
    "    font=dict(size=16),\n",
    ")\n",
    "# fig.write_image(f\"{workdir}/plots/6jet_mass_RF_cut_05_fit.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for cut in (0.8, 0.90, 0.95, 0.99):\n",
    "    scores = mass_score_cut(m6j_test, scores_test_rf, cut, prc=True)\n",
    "    counts = {k: len(v) * const.CROSS_SECTION_ATLAS_130_85[k] for k, v in scores.items()}\n",
    "    res[cut] = counts\n",
    "df_counts_rf = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_counts = df_counts_rf.iloc[:-1].T.sum(axis=1)\n",
    "sig_counts = df_counts_rf.iloc[-1]\n",
    "s_over_b = sig_counts / bkg_counts\n",
    "s_over_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add s_over_b as a row\n",
    "df_counts_rf.loc[\"BKG:sum\"] = bkg_counts\n",
    "df_counts_rf.loc[\"S/B\"] = s_over_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_histogram_with_double_gaussian_fit(\n",
    "    mass_score_cut(m6j_test, scores_test_gb, 0.99, prc=True),\n",
    "    20,\n",
    "    clip_top_prc=100,\n",
    "    cross=const.CROSS_SECTION_ATLAS_130_85,\n",
    ")\n",
    "# fig = make_histogram(mass_score_cut(m6j_test, scores_test_gb, 0.95, prc=False), 20, clip_top_prc=100)\n",
    "fig.update_layout(\n",
    "    title=\"6-jet Mass\",\n",
    "    xaxis_title=\"Invariant Mass [GeV]\",\n",
    "    yaxis_title_text=\"count x sigma\",\n",
    "    # yaxis_type=\"log\",\n",
    "    barmode=\"stack\",\n",
    "    bargap=0,\n",
    "    width=1600 * (2 / 3),\n",
    "    height=1400 * (2 / 3),\n",
    ")\n",
    "fig.update_legends(\n",
    "    title_text=\"\",\n",
    "    itemsizing=\"constant\",\n",
    "    yanchor=\"top\",\n",
    "    y=0.99,\n",
    "    xanchor=\"left\",\n",
    "    x=0.01,\n",
    "    font=dict(size=16),\n",
    ")\n",
    "# fig.write_image(f\"{workdir}/plots/6jet_mass_GB_cut_05_fit.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for cut in (0.8, 0.90, 0.95, 0.99):\n",
    "    scores = mass_score_cut(m6j_test, scores_test_gb, cut, prc=True)\n",
    "    counts = {k: len(v) for k, v in scores.items()}\n",
    "    res[cut] = counts\n",
    "df_counts_gb = pd.DataFrame(res)\n",
    "df_counts_gb\n",
    "\n",
    "bkg_counts = df_counts_gb.iloc[:-1].T.sum(axis=1)\n",
    "sig_counts = df_counts_gb.iloc[-1]\n",
    "s_over_b = sig_counts / bkg_counts\n",
    "\n",
    "# add s_over_b as a row\n",
    "df_counts_gb.loc[\"BKG:sum\"] = bkg_counts\n",
    "df_counts_gb.loc[\"S/B\"] = s_over_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
