{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pendulum\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "\n",
    "import diquark.constants as const\n",
    "from diquark.plotting import make_histogram, make_histogram_with_double_gaussian_fit\n",
    "from diquark.helpers import mass_score_cut\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tfkl = tf.keras.layers\n",
    "tfk = tf.keras\n",
    "\n",
    "if os.getcwd().split(\"/\")[-1] == \"notebooks\":\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = pendulum.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "workdir = f\"models/run_{run_id}\"\n",
    "\n",
    "if not os.path.exists(workdir):\n",
    "    os.makedirs(workdir)\n",
    "    os.makedirs(f\"{workdir}/plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/full_sample.parquet\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate signal and background events\n",
    "df_bkg = df[df[\"target\"] == 0]\n",
    "df_sig = df[df[\"target\"] == 1]\n",
    "\n",
    "# Separate the signal events\n",
    "df_sig_train = df_sig.sample(frac=0.8, random_state=0)\n",
    "df_sig_test = df_sig.drop(df_sig_train.index)\n",
    "\n",
    "# Split the background events\n",
    "df_bkg_train = df_bkg.sample(frac=0.8, random_state=0)\n",
    "df_bkg_test = df_bkg.drop(df_bkg_train.index)\n",
    "\n",
    "# Oversample the signal class in the training set to match the number of background instances\n",
    "df_sig_train_oversampled = resample(\n",
    "    df_sig_train,\n",
    "    replace=True,  # sample with replacement\n",
    "    n_samples=len(df_bkg_train),  # match number in majority class\n",
    "    random_state=0,\n",
    ")  # reproducible results\n",
    "\n",
    "# Combine the oversampled signal class with the background class to form the training set\n",
    "df_train = pd.concat([df_sig_train_oversampled, df_bkg_train])\n",
    "\n",
    "# Combine signal and background test sets\n",
    "df_test = pd.concat([df_sig_test, df_bkg_test])\n",
    "\n",
    "# Shuffle the training and test sets\n",
    "df_train = shuffle(df_train, random_state=0)\n",
    "df_test = shuffle(df_test, random_state=0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Separate features and targets\n",
    "x_train = df_train.drop([\"target\", \"Truth\", \"inv_mass\"], axis=1).to_numpy()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = df_test.drop([\"target\", \"Truth\", \"inv_mass\"], axis=1).to_numpy()\n",
    "x_test = scaler.transform(x_test)\n",
    "y_train = df_train[\"target\"].to_numpy()\n",
    "y_test = df_test[\"target\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_parquet(f\"{workdir}/train.parquet\")\n",
    "df_test.to_parquet(f\"{workdir}/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df_test[[\"Truth\", \"inv_mass\"]].reset_index(drop=True)\n",
    "train_df = df_train[[\"Truth\", \"inv_mass\"]].reset_index(drop=True)\n",
    "\n",
    "m6j_test = {}\n",
    "for key in test_df[\"Truth\"].unique():\n",
    "    m6j_test[key] = test_df[test_df[\"Truth\"] == key][\"inv_mass\"].to_numpy()\n",
    "\n",
    "m6j_train = {}\n",
    "for key in train_df[\"Truth\"].unique():\n",
    "    m6j_train[key] = train_df[train_df[\"Truth\"] == key][\"inv_mass\"].to_numpy()\n",
    "\n",
    "joblib.dump(m6j_test, f\"{workdir}/m6j_test.data.joblib\")\n",
    "joblib.dump(m6j_train, f\"{workdir}/m6j_train.data.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(f\"{workdir}/data.npz\", x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_instance = tfk.metrics.FalsePositives(name=\"fp\")\n",
    "\n",
    "model = tfk.Sequential(\n",
    "    [\n",
    "        tfkl.InputLayer(input_shape=(76)),\n",
    "        tfkl.Dense(64, activation=\"relu\", name=\"dense_1\"),\n",
    "        tfkl.Dropout(0.2, name=\"dropout_1\"),\n",
    "        tfkl.Dense(32, activation=\"relu\", name=\"dense_2\"),\n",
    "        tfkl.Dropout(0.1, name=\"dropout_2\"),\n",
    "        tfkl.Dense(32, activation=\"relu\", name=\"dense_3\"),\n",
    "        tfkl.Dense(1, activation=\"sigmoid\", name=\"output\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[metric_instance, \"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train, epochs=5, batch_size=128, validation_data=(x_test, y_test), verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=history.epoch,\n",
    "        y=history.history[\"loss\"],\n",
    "        name=\"Training Loss\",\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"blue\"),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=history.epoch,\n",
    "        y=history.history[\"val_loss\"],\n",
    "        name=\"Validation Loss\",\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"red\"),\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"Training and Validation Loss\",\n",
    "    xaxis_title=\"Epoch\",\n",
    "    yaxis_title=\"Loss\",\n",
    "    width=800,\n",
    "    height=600,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{workdir}/model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nn = model.predict(x_test)\n",
    "scores_test_nn = {}\n",
    "for key in test_df[\"Truth\"].unique():\n",
    "    scores_test_nn[key] = y_pred_nn.flatten()[test_df[test_df[\"Truth\"] == key].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_histogram(scores_test_nn, 50, clip_top_prc=100, clip_bottom_prc=0, cross=None)\n",
    "fig.update_layout(\n",
    "    title_text=\"Test scores distribution\",\n",
    "    barmode=\"stack\",\n",
    "    yaxis_type=\"log\",\n",
    "    xaxis_title=\"Random Forest Output\",\n",
    "    yaxis_title=\"Count\",\n",
    ")\n",
    "fig.write_image(f\"{workdir}/plots/NN-output.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_histogram_with_double_gaussian_fit(\n",
    "    mass_score_cut(m6j_test, scores_test_nn, cut=0.99, prc=True),\n",
    "    20,\n",
    "    clip_top_prc=100,\n",
    "    cross=const.CROSS_SECTION_ATLAS_130_85,\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"6-jet Mass\",\n",
    "    xaxis_title=\"Invariant Mass [GeV]\",\n",
    "    yaxis_title_text=\"count x sigma\",\n",
    "    barmode=\"stack\",\n",
    "    bargap=0,\n",
    "    width=1600 * (5 / 6),\n",
    "    height=900 * (5 / 6),\n",
    ")\n",
    "fig.write_image(f\"{workdir}/plots/6jet_mass_NN_cut_fit.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_jobs=-1).fit(x_train, y_train)\n",
    "print(\"RFC trained\")\n",
    "joblib.dump(rf_clf, f\"{workdir}/rfc.joblib\", compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = xgb.XGBClassifier(tree_method=\"hist\").fit(x_train, y_train)\n",
    "print(\"GBC trained\")\n",
    "joblib.dump(gb_clf, f\"{workdir}/gbc.joblib\", compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gb = gb_clf.predict_proba(x_test)[:, 1]\n",
    "y_pred_rf = rf_clf.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = [const.CROSS_SECTION_ATLAS_130_85[label] for label in test_df[\"Truth\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the first model\n",
    "precision_nn, recall_nn, thresholds_nn = precision_recall_curve(y_test, y_pred_nn)\n",
    "# precision_nn, recall_nn, thresholds_nn = precision_recall_curve(y_test, y_pred_nn, sample_weight=sample_weights)\n",
    "pr_auc_nn = auc(recall_nn, precision_nn)\n",
    "\n",
    "# For the Gradient Boosting model\n",
    "precision_gb, recall_gb, thresholds_gb = precision_recall_curve(y_test, y_pred_gb)\n",
    "# precision_gb, recall_gb, thresholds_gb = precision_recall_curve(y_test, y_pred_gb, sample_weight=sample_weights)\n",
    "pr_auc_gb = auc(recall_gb, precision_gb)\n",
    "\n",
    "# For the Random Forest model\n",
    "precision_rf, recall_rf, thresholds_rf = precision_recall_curve(y_test, y_pred_rf)\n",
    "# precision_rf, recall_rf, thresholds_rf = precision_recall_curve(y_test, y_pred_rf, sample_weight=sample_weights)\n",
    "pr_auc_rf = auc(recall_rf, precision_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=recall_gb,\n",
    "        y=precision_gb,\n",
    "        customdata=thresholds_gb,\n",
    "        hovertemplate=\"Threshold=%{customdata}<br>Recall=%{x}<br>Precision=%{y}\",\n",
    "        mode=\"lines\",\n",
    "        name=f\"BDT - AUC={pr_auc_gb:.3f}\",\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=recall_rf,\n",
    "        y=precision_rf,\n",
    "        customdata=thresholds_rf,\n",
    "        hovertemplate=\"Threshold=%{customdata}<br>Recall=%{x}<br>Precision=%{y}\",\n",
    "        mode=\"lines\",\n",
    "        name=f\"RF - AUC={pr_auc_rf:.3f}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=recall_nn,\n",
    "        y=precision_nn,\n",
    "        customdata=thresholds_nn,\n",
    "        hovertemplate=\"Threshold=%{customdata}<br>Recall=%{x}<br>Precision=%{y}\",\n",
    "        mode=\"lines\",\n",
    "        name=f\"NN - AUC={pr_auc_nn:.3f}\",\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"Cross-Section Weighted Precision-Recall Curves\",\n",
    "    xaxis_title=\"Recall\",\n",
    "    yaxis_title=\"Precision\",\n",
    "    width=1200 * (2 / 3),\n",
    "    height=800 * (2 / 3),\n",
    ")\n",
    "fig.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "fig.write_image(f\"{workdir}/plots/PR-curve.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from Random Forest\n",
    "rf_importance = rf_clf.feature_importances_\n",
    "gb_importance = gb_clf.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = df_train.drop([\"target\", \"Truth\", \"inv_mass\"], axis=1).columns\n",
    "\n",
    "# Create a grouped bar chart\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add bars for Random Forest\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=feature_names,\n",
    "        y=rf_importance,\n",
    "        name=\"Random Forest\",\n",
    "        offsetgroup=1,\n",
    "        marker=dict(color=\"#E4D91B\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add bars for Random Forest\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=feature_names,\n",
    "        y=gb_importance,\n",
    "        name=\"Gradient Boosting\",\n",
    "        offsetgroup=2,\n",
    "        marker=dict(color=\"#D91BE4\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Feature Importances for Random Forest\",\n",
    "    xaxis_title=\"Features\",\n",
    "    yaxis_title=\"Importance Value\",\n",
    "    # legend_title='Classifier',\n",
    "    xaxis=dict(tickangle=45),\n",
    "    barmode=\"group\",\n",
    "    width=1200,\n",
    ")\n",
    "fig.write_image(f\"{workdir}/plots/feature_importances.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_test_rf = {}\n",
    "for key in test_df[\"Truth\"].unique():\n",
    "    scores_test_rf[key] = y_pred_rf.flatten()[test_df[test_df[\"Truth\"] == key].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_histogram(scores_test_rf, 50, clip_top_prc=100, clip_bottom_prc=0, cross=None)\n",
    "fig.update_layout(\n",
    "    title_text=\"Data Sample Content by Model Output Cut\",\n",
    "    barmode=\"stack\",\n",
    "    yaxis_type=\"log\",\n",
    "    xaxis_title=\"RF Output\",\n",
    "    yaxis_title=\"Probability Density\",\n",
    "    width=1600 * (5 / 6),\n",
    "    height=900 * (5 / 6),\n",
    ")\n",
    "fig.write_image(f\"{workdir}/plots/RF-output.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_histogram_with_double_gaussian_fit(\n",
    "    mass_score_cut(m6j_test, scores_test_rf, 0.99, prc=True),\n",
    "    20,\n",
    "    clip_top_prc=100,\n",
    "    cross=const.CROSS_SECTION_ATLAS_130_85,\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"6-jet Mass\",\n",
    "    xaxis_title=\"Invariant Mass [GeV]\",\n",
    "    yaxis_title_text=\"count x sigma\",\n",
    "    # yaxis_type=\"log\",\n",
    "    barmode=\"stack\",\n",
    "    bargap=0,\n",
    "    width=1600 * (2 / 3),\n",
    "    height=900 * (2 / 3),\n",
    ")\n",
    "fig.update_legends(\n",
    "    title_text=\"\",\n",
    "    itemsizing=\"constant\",\n",
    "    yanchor=\"top\",\n",
    "    y=0.99,\n",
    "    xanchor=\"left\",\n",
    "    x=0.01,\n",
    "    font=dict(size=16),\n",
    ")\n",
    "# fig.write_image(f\"{workdir}/plots/6jet_mass_RF_cut_05_fit.pdf\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
