{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "\n",
    "import diquark.constants as const\n",
    "from diquark.plotting import make_histogram, make_histogram_with_double_gaussian_fit\n",
    "from diquark.helpers import mass_score_cut\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tfkl = tf.keras.layers\n",
    "tfk = tf.keras\n",
    "\n",
    "if os.getcwd().split(\"/\")[-1] == \"notebooks\":\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the latest workdir\n",
    "PREFIXES = [\n",
    "    \"run_ATLAS_130_65\",\n",
    "    \"run_ATLAS_130_80\",\n",
    "    \"run_ATLAS_136_65\",\n",
    "    \"run_ATLAS_136_80\",\n",
    "    \"run_CMS_130_65\",\n",
    "    \"run_CMS_130_80\",\n",
    "    \"run_CMS_136_65\",\n",
    "    \"run_CMS_136_80\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_workdir(prefix=\"run_ATLAS_130_65\"):\n",
    "    return sorted([d for d in os.listdir(\"models\") if d.startswith(prefix)])[-1]\n",
    "\n",
    "\n",
    "data = []\n",
    "fits = []\n",
    "pr = []\n",
    "for prefix in tqdm(PREFIXES):\n",
    "    workdir = get_workdir(prefix)\n",
    "    df = pd.read_csv(f\"models/{workdir}/counts_rf.csv\")\n",
    "    df = df.melt(id_vars=[\"Unnamed: 0\"], var_name=\"cut\", value_name=\"counts\")\n",
    "    df[\"detector\"] = prefix.split(\"_\")[1]\n",
    "    df[\"ECM\"] = int(prefix.split(\"_\")[2]) / 10\n",
    "    df[\"mSuu\"] = (int(prefix.split(\"_\")[3]) / 10) + 0.5\n",
    "    data.append(df)\n",
    "\n",
    "    with open(f\"models/{workdir}/fits.json\", \"r\") as f:\n",
    "        js = json.load(f)\n",
    "        js[\"detector\"] = prefix.split(\"_\")[1]\n",
    "        js[\"ECM\"] = int(prefix.split(\"_\")[2]) / 10\n",
    "        js[\"mSuu\"] = (int(prefix.split(\"_\")[3]) / 10) + 0.5\n",
    "        fits.append(js)\n",
    "\n",
    "    with open(f\"models/{workdir}/pr_curves.json\", \"r\") as f:\n",
    "        js = json.load(f)\n",
    "        js[\"detector\"] = prefix.split(\"_\")[1]\n",
    "        js[\"ECM\"] = int(prefix.split(\"_\")[2]) / 10\n",
    "        js[\"mSuu\"] = (int(prefix.split(\"_\")[3]) / 10) + 0.5\n",
    "        pr.append(js)\n",
    "\n",
    "\n",
    "counts_df = pd.concat(data).rename(columns={\"Unnamed: 0\": \"label\"})\n",
    "fits_df = pd.json_normalize(fits)\n",
    "pr_df = pd.json_normalize(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df.to_csv(\"models/counts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    counts_df[counts_df[\"label\"] == \"S/B\"],\n",
    "    x=\"cut\",\n",
    "    y=\"counts\",\n",
    "    color=\"detector\",\n",
    "    symbol=\"ECM\",\n",
    "    line_dash=\"ECM\",\n",
    "    facet_row=\"mSuu\",\n",
    "    markers=True,\n",
    ")\n",
    "fig.update_yaxes(type=\"log\")\n",
    "fig.for_each_yaxis(lambda a: a.title.update(text=\"S/B\"))\n",
    "fig.update_layout(\n",
    "    title=\"S/B vs. discriminator cut for different detectors and ECMs\",\n",
    "    width=600,\n",
    "    height=600,\n",
    ")\n",
    "# fig.update_xaxes(title=\"cut\")\n",
    "# make y-axes be named \"S/B\"\n",
    "fig.write_image(\"sb_vs_cut.pdf\")\n",
    "fig.show()\n",
    "# fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = pd.wide_to_long(\n",
    "    pr_df.reset_index(),\n",
    "    stubnames=[\"precision\", \"recall\", \"threshold\", \"auc\"],\n",
    "    i=\"index\",\n",
    "    j=\"model\",\n",
    "    sep=\"_\",\n",
    "    suffix=r\"\\w+\",\n",
    ").reset_index()\n",
    "\n",
    "# Now, extract the model type into a new column\n",
    "long_df[\"model\"] = long_df[\"model\"].map({\"nn\": \"NN\", \"gb\": \"GB\", \"rf\": \"RF\"})\n",
    "long_df = long_df.drop(columns=[\"index\"])\n",
    "# Optionally, sort or reorganize the DataFrame as needed\n",
    "# long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    long_df,\n",
    "    x=\"detector\",\n",
    "    y=\"auc\",\n",
    "    color=\"model\",\n",
    "    barmode=\"group\",\n",
    "    facet_row=\"mSuu\",\n",
    "    facet_col=\"ECM\",\n",
    ")\n",
    "fig.update_yaxes(type=\"log\")\n",
    "fig.update_layout(\n",
    "    title=\"AUC for different detectors and ECMs\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_df.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Prepare data for plotting\n",
    "models = [\"nn\", \"rf\", \"gb\"]\n",
    "colors = [\"blue\", \"green\", \"red\"]\n",
    "# x = range(len(fits_df))\n",
    "\n",
    "\n",
    "# Plot each model with error bars\n",
    "for model, color in zip(models, colors):\n",
    "    mean = fits_df[f\"{model}.mean\"]\n",
    "    std = fits_df[f\"{model}.std\"]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=fits_df[\"mSuu\"].astype(str)\n",
    "            + \" TeV, ECM=\"\n",
    "            + fits_df[\"ECM\"].astype(str)\n",
    "            + \" TeV\"\n",
    "            + \" (\"\n",
    "            + fits_df[\"detector\"]\n",
    "            + \")\",\n",
    "            y=mean,\n",
    "            error_y=dict(type=\"data\", array=std, visible=True),\n",
    "            mode=\"markers\",\n",
    "            name=f\"{model.upper()} mean Â± std\",\n",
    "            marker=dict(color=color),\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"m6j fit Mean and Standard Deviation by Model and mSuu\",\n",
    "    xaxis_title=\"mSuu (Detector)\",\n",
    "    yaxis_title=\"Mean Value\",\n",
    "    legend_title=\"Model\",\n",
    "    xaxis=dict(tickangle=45),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecms = counts_df[\"ECM\"].unique()\n",
    "msuus = counts_df[\"mSuu\"].unique()\n",
    "detectors = counts_df[\"detector\"].unique()\n",
    "\n",
    "msuus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table(df, luminosity=3000):\n",
    "    # Extract unique values for ECM, mSuu, and detector to structure the table\n",
    "    ecms = df[\"ECM\"].unique()\n",
    "    msuus = df[\"mSuu\"].unique()\n",
    "    detectors = df[\"detector\"].unique()\n",
    "    df[\"cut\"] = df[\"cut\"].astype(float)\n",
    "\n",
    "    # Start the LaTeX table format\n",
    "    latex_str = \"begin{tabular}{|l|c|c|c|c|}\\n\\\\hline\\n\"\n",
    "    latex_str += \" & \\\\multicolumn{4}{c|}{Counts for cuts} \\\\\\\\ \\\\cline{2-5}\\n\"\n",
    "    latex_str += \"Event & 0.80 & 0.90 & 0.95 & 0.99 \\\\\\\\ \\\\hline\\n\"\n",
    "\n",
    "    # Loop over each combination of ECM, mSuu, and detector\n",
    "    for detector in detectors:\n",
    "        for ecm in ecms:\n",
    "            for msuu in msuus:\n",
    "                # Filter data for current combination\n",
    "                filtered_data = df[\n",
    "                    (df[\"ECM\"] == ecm) & (df[\"mSuu\"] == msuu) & (df[\"detector\"] == detector)\n",
    "                ]\n",
    "                if not filtered_data.empty:\n",
    "                    # For each cut, find the sum of BKG, SIG, and calculate S/B\n",
    "                    for cut in [0.8, 0.90, 0.95, 0.99]:\n",
    "                        bkg_sum = (\n",
    "                            filtered_data[\n",
    "                                (filtered_data[\"label\"] == \"BKG:sum\")\n",
    "                                & (filtered_data[\"cut\"] == cut)\n",
    "                            ][\"counts\"].values[0]\n",
    "                            * luminosity\n",
    "                        )\n",
    "                        sig_sum = (\n",
    "                            filtered_data[\n",
    "                                (filtered_data[\"label\"] == \"SIG:Suu\")\n",
    "                                & (filtered_data[\"cut\"] == cut)\n",
    "                            ][\"counts\"].values[0]\n",
    "                            * luminosity\n",
    "                        )\n",
    "                        sb_ratio = filtered_data[\n",
    "                            (filtered_data[\"label\"] == \"S/B\") & (filtered_data[\"cut\"] == cut)\n",
    "                        ][\"counts\"].values[0]\n",
    "                        # Add to LaTeX string\n",
    "                        latex_str += f\"{detector}, ECM={ecm}, mSuu={msuu} & {bkg_sum:.2e} & {sig_sum:.2e} & {sb_ratio:.2e} \\\\\\\\ \\\\hline\\n\"\n",
    "\n",
    "    # Close the LaTeX table format\n",
    "    latex_str += \"\\\\end{tabular}\"\n",
    "\n",
    "    return latex_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_latex_table(counts_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table_with_multirow(df, luminosity=3000):\n",
    "    # Ensure 'cut' is of type float\n",
    "    df[\"cut\"] = df[\"cut\"].astype(float)\n",
    "\n",
    "    # Initialize the LaTeX table format with headers for each distinct category\n",
    "    latex_str = \"\\\\begin{tabular}{|l|l|l|c|c|c|c|}\\n\\\\hline\\n\"\n",
    "    latex_str += \"Detector & ECM & mSuu & \\\\multicolumn{4}{c|}{Counts for cuts} \\\\\\\\ \\\\cline{4-7}\\n\"\n",
    "    latex_str += \" & & & 0.80 & 0.90 & 0.95 & 0.99 \\\\\\\\ \\\\hline\\n\"\n",
    "\n",
    "    # Group by detector, ECM, mSuu to count occurrences\n",
    "    grouped = df.groupby([\"detector\", \"ECM\", \"mSuu\"])\n",
    "\n",
    "    for (detector, ecm, msuu), group in grouped:\n",
    "        num_rows = len(group[\"cut\"].unique())\n",
    "        first_row = True  # Indicator for the first row of each group\n",
    "\n",
    "        for cut in [0.8, 0.90, 0.95, 0.99]:\n",
    "            bkg_sum = sig_sum = sb_ratio = 0  # Default values\n",
    "            if cut in group[\"cut\"].values:\n",
    "                # Calculate values only if the cut exists in the group\n",
    "                bkg_sum = (\n",
    "                    group[(group[\"label\"] == \"BKG:sum\") & (group[\"cut\"] == cut)][\"counts\"].values[0]\n",
    "                    * luminosity\n",
    "                )\n",
    "                sig_sum = (\n",
    "                    group[(group[\"label\"] == \"SIG:Suu\") & (group[\"cut\"] == cut)][\"counts\"].values[0]\n",
    "                    * luminosity\n",
    "                )\n",
    "                sb_ratio = group[(group[\"label\"] == \"S/B\") & (group[\"cut\"] == cut)][\n",
    "                    \"counts\"\n",
    "                ].values[0]\n",
    "\n",
    "            if first_row:\n",
    "                # Use \\multirow for the first row in each group\n",
    "                latex_str += f\"\\\\multirow{{{num_rows}}}{{*}}{{{detector}}} & \\\\multirow{{{num_rows}}}{{*}}{{{ecm}}} & \\\\multirow{{{num_rows}}}{{*}}{{{msuu}}} & {cut} & {bkg_sum:.2e} & {sig_sum:.2e} & {sb_ratio:.2e} \\\\\\\\ \\\\cline{4-7}\\n\"\n",
    "                first_row = False\n",
    "            else:\n",
    "                # Only include cut-specific data in subsequent rows\n",
    "                latex_str += f\" & & & {cut} & {bkg_sum:.2e} & {sig_sum:.2e} & {sb_ratio:.2e} \\\\\\\\ \\\\cline{4-7}\\n\"\n",
    "\n",
    "    # Close the LaTeX table format\n",
    "    latex_str += \"\\\\end{tabular}\"\n",
    "\n",
    "    return latex_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_latex_table_with_multirow(counts_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table_with_multirow_corrected(df, luminosity=3000):\n",
    "    # Convert 'cut' to float to ensure proper sorting and comparison\n",
    "    df[\"cut\"] = df[\"cut\"].astype(float)\n",
    "\n",
    "    # Initialize the LaTeX table format with headers\n",
    "    latex_str = \"\\\\begin{tabular}{|l|l|l|c|c|c|c|}\\n\\\\hline\\n\"\n",
    "    latex_str += (\n",
    "        \"Detector & ECM & mSuu & \\\\multicolumn{4}{c|}{Event Counts for cuts} \\\\\\\\ \\\\cline{4-7}\\n\"\n",
    "    )\n",
    "    latex_str += \" & & & cut & Background & Signal & S/B \\\\\\\\ \\\\hline\\n\"\n",
    "\n",
    "    # Calculate the number of rows needed for the multirow command dynamically\n",
    "    detector_group = df.groupby([\"detector\"])\n",
    "    for detector, detector_df in detector_group:\n",
    "        detector_rows = len(detector_df.groupby([\"ECM\", \"mSuu\"]).size())\n",
    "        ecm_group = detector_df.groupby([\"ECM\"])\n",
    "        for ecm, ecm_df in ecm_group:\n",
    "            ecm_rows = len(ecm_df.groupby([\"mSuu\"]).size())\n",
    "            msuu_group = ecm_df.groupby([\"mSuu\"])\n",
    "            for msuu, msuu_df in msuu_group:\n",
    "                msuu_rows = len(msuu_df[\"cut\"].unique())\n",
    "                first_row = True\n",
    "                for _, row in msuu_df.iterrows():\n",
    "                    cut = row[\"cut\"]\n",
    "                    bkg_sum = row[\"counts\"] if row[\"label\"] == \"BKG:sum\" else 0\n",
    "                    sig_sum = row[\"counts\"] if row[\"label\"] == \"SIG:Suu\" else 0\n",
    "                    sb_ratio = row[\"counts\"] if row[\"label\"] == \"S/B\" else 0\n",
    "                    if first_row:\n",
    "                        latex_str += f\"\\\\multirow{{{detector_rows}}}{{*}}{{{detector}}} & \\\\multirow{{{ecm_rows}}}{{*}}{{{ecm}}} & \\\\multirow{{{msuu_rows}}}{{*}}{{{msuu}}} & {cut} & {bkg_sum:.2e} & {sig_sum:.2e} & {sb_ratio:.2e} \\\\\\\\\\n\"\n",
    "                        first_row = False\n",
    "                    else:\n",
    "                        latex_str += (\n",
    "                            f\" & & & {cut} & {bkg_sum:.2e} & {sig_sum:.2e} & {sb_ratio:.2e} \\\\\\\\\\n\"\n",
    "                        )\n",
    "                detector_rows -= msuu_rows\n",
    "                if detector_rows > 0:  # If there are more rows to cover for this detector\n",
    "                    latex_str += \"\\\\cline{2-7}\\n\"\n",
    "            if ecm_rows > msuu_rows:  # Adjust for next ECM if necessary\n",
    "                latex_str += \"\\\\cline{3-7}\\n\"\n",
    "\n",
    "    latex_str += \"\\\\hline\\n\\\\end{tabular}\"\n",
    "\n",
    "    return latex_str\n",
    "\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "latex_table_corrected = generate_latex_table_with_multirow_corrected(counts_df)\n",
    "print(latex_table_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = counts_df[\n",
    "    (counts_df[\"ECM\"] == 13.6) & (counts_df[\"mSuu\"] == 7.0) & (counts_df[\"detector\"] == \"ATLAS\")\n",
    "][[\"label\", \"cut\", \"counts\"]]\n",
    "df_0.loc[df_0[\"label\"] != \"S/B\", \"counts\"]  # *= 3000 / 100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0.pivot(index=\"label\", columns=\"cut\", values=\"counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For an integrated luminosity of $3000 fb^{-1}$ expected by the end of the HL-LHC phase, we are able to isolate high purity samples $S/B \\ge 100$ containing hundreds of events."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
