{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "\n",
    "import diquark.constants as const\n",
    "from diquark.plotting import make_histogram, make_histogram_with_double_gaussian_fit\n",
    "from diquark.helpers import mass_score_cut\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tfkl = tf.keras.layers\n",
    "tfk = tf.keras\n",
    "\n",
    "if os.getcwd().split(\"/\")[-1] == \"notebooks\":\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the latest workdir\n",
    "PREFIXES = [\n",
    "\n",
    "    # \"run_ATLAS_130_55\",\n",
    "    # \"run_ATLAS_136_55\",\n",
    "    # \"run_CMS_130_55\",\n",
    "    # \"run_CMS_136_55\",\n",
    "\n",
    "    # \"run_ATLAS_130_60\",\n",
    "    # \"run_ATLAS_136_60\",\n",
    "    # \"run_CMS_130_60\",\n",
    "    # \"run_CMS_136_60\",\n",
    "\n",
    "    # \"run_ATLAS_130_65\",\n",
    "    # \"run_ATLAS_136_65\",\n",
    "    # \"run_CMS_130_65\",\n",
    "    # \"run_CMS_136_65\",\n",
    "\n",
    "    # \"run_ATLAS_130_70\",\n",
    "    # \"run_ATLAS_136_70\",\n",
    "    # \"run_CMS_130_70\",\n",
    "    # \"run_CMS_136_70\",\n",
    "    \n",
    "    # \"run_ATLAS_130_80\",\n",
    "    # \"run_ATLAS_136_80\",\n",
    "    # \"run_CMS_130_80\",\n",
    "    # \"run_CMS_136_80\",\n",
    "\n",
    "    \"run_ATLAS_140_55\",\n",
    "    \"run_ATLAS_140_60\",\n",
    "    \"run_ATLAS_140_65\",\n",
    "    \"run_ATLAS_140_70\",\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "def get_workdir(prefix=\"run_ATLAS_130_65\"):\n",
    "    return sorted([d for d in os.listdir(\"models\") if d.startswith(prefix)])[-1]\n",
    "\n",
    "\n",
    "data = []\n",
    "fits = []\n",
    "pr = []\n",
    "for prefix in tqdm(PREFIXES):\n",
    "    workdir = get_workdir(prefix)\n",
    "    print(workdir)\n",
    "    df_new = pd.read_csv(f\"models/{workdir}/counts_rf.csv\")\n",
    "    df = df_new.drop(columns=[\"0.99\"])\n",
    "    df = df.melt(id_vars=[\"Unnamed: 0\"], var_name=\"cut\", value_name=\"counts\")\n",
    "    df[\"detector\"] = prefix.split(\"_\")[1]\n",
    "    df[\"ECM\"] = int(prefix.split(\"_\")[2]) / 10\n",
    "    df[\"mSuu\"] = str((int(prefix.split(\"_\")[3]) / 10) + 1.5) + \" TeV\"\n",
    "    data.append(df)\n",
    "\n",
    "    with open(f\"models/{workdir}/fits.json\", \"r\") as f:\n",
    "        js = json.load(f)\n",
    "        js[\"detector\"] = prefix.split(\"_\")[1]\n",
    "        js[\"ECM\"] = int(prefix.split(\"_\")[2]) / 10\n",
    "        js[\"mSuu\"] = (int(prefix.split(\"_\")[3]) / 10) + 1.5\n",
    "        fits.append(js)\n",
    "\n",
    "    with open(f\"models/{workdir}/pr_curves.json\", \"r\") as f:\n",
    "        js = json.load(f)\n",
    "        js[\"detector\"] = prefix.split(\"_\")[1]\n",
    "        js[\"ECM\"] = int(prefix.split(\"_\")[2]) / 10\n",
    "        js[\"mSuu\"] = (int(prefix.split(\"_\")[3]) / 10) + 1.5\n",
    "        pr.append(js)\n",
    "\n",
    "\n",
    "counts_df = pd.concat(data).rename(columns={\"Unnamed: 0\": \"label\"})\n",
    "fits_df = pd.json_normalize(fits)\n",
    "pr_df = pd.json_normalize(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df.to_csv(\"models/counts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    counts_df[counts_df[\"label\"] == \"S/B\"],\n",
    "    x=\"cut\",\n",
    "    y=\"counts\",\n",
    "    color=\"mSuu\",\n",
    "    # symbol=\"ECM\",\n",
    "    # line_dash=\"ECM\",\n",
    "    # facet_row=\"mSuu\",\n",
    "    markers=True,\n",
    ")\n",
    "\n",
    "\n",
    "# update y axis title to be horizontally positioned\n",
    "fig.for_each_yaxis(lambda a: a.title.update(text=\"\"))\n",
    "fig.update_layout(\n",
    "    annotations=[\n",
    "        dict(\n",
    "            x=-0.1,  # position x-axis relative to the plot area (negative value to move outside the plot area)\n",
    "            y=0.5,  # position y-axis at the middle\n",
    "            xref='paper',\n",
    "            yref='paper',\n",
    "            text='S/B',\n",
    "            showarrow=False,\n",
    "            textangle=0,  # keep text horizontal\n",
    "            font=dict(size=12)  # adjust font size if needed\n",
    "        )\n",
    "    ],\n",
    "    margin=dict(l=20)  # add some margin on the left side\n",
    ")\n",
    "\n",
    "# Update ticks text - not log format\n",
    "tickvals = [0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10]\n",
    "ticktext = ['0.0005', '0.001', '0.002', '0.005', '0.01', '0.02', '0.05', '0.1', '0.2', '0.5', '1', '2', '5', '10']\n",
    "\n",
    "fig.update_layout(\n",
    "    yaxis=dict(\n",
    "        type='log',\n",
    "        tickvals=tickvals,\n",
    "        ticktext=ticktext\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update title\n",
    "fig.update_layout(\n",
    "    title=str(counts_df['detector'].iloc[0]),\n",
    "    title_x = 0.535,\n",
    "    title_y = 0.89 if str(counts_df['detector'].iloc[0]) == \"ATLAS\" else 0.864, # Adjust title y pos depending on detector used\n",
    "    width=600,\n",
    "    height=600,\n",
    "    legend=dict(title = r\"$S_{uu} \\text{ mass}$\", yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01),\n",
    "    # legend=dict(title = \"$m_{S}$\", yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01),\n",
    "    \n",
    ")\n",
    "\n",
    "fig.update_xaxes(title=\"Discriminator cut\")\n",
    "\n",
    "\n",
    "# fig.for_each_annotation(update_annotations)\n",
    "fig.write_image(\"ATLAS_sb_vs_cut_140.pdf\")\n",
    "fig.show()\n",
    "# fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = pd.wide_to_long(\n",
    "    pr_df.reset_index(),\n",
    "    stubnames=[\"precision\", \"recall\", \"threshold\", \"auc\"],\n",
    "    i=\"index\",\n",
    "    j=\"model\",\n",
    "    sep=\"_\",\n",
    "    suffix=r\"\\w+\",\n",
    ").reset_index()\n",
    "\n",
    "# Now, extract the model type into a new column\n",
    "long_df[\"model\"] = long_df[\"model\"].map({\"nn\": \"NN\", \"gb\": \"GB\", \"rf\": \"RF\"})\n",
    "long_df = long_df.drop(columns=[\"index\"])\n",
    "# Optionally, sort or reorganize the DataFrame as needed\n",
    "# long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm7_mask = (long_df[\"mSuu\"] == 7.0) & (long_df[\"ECM\"] == 13.6)\n",
    "\n",
    "df7 = long_df[rm7_mask]\n",
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1, subplot_titles=(\"ATLAS\", \"CMS\"), vertical_spacing=0.1, shared_xaxes=True\n",
    ")\n",
    "print(\"done1\")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df7[(df7[\"detector\"] == \"ATLAS\") & (df7[\"model\"] == \"NN\")][\"recall\"].to_list()[0],\n",
    "        y=df7[(df7[\"detector\"] == \"ATLAS\") & (df7[\"model\"] == \"NN\")][\"precision\"].to_list()[0],\n",
    "        customdata=df7[(df7[\"detector\"] == \"ATLAS\") & (df7[\"model\"] == \"NN\")][\n",
    "            \"threshold\"\n",
    "        ].to_list()[0],\n",
    "        hovertemplate=\"Threshold=%{customdata}<br>Recall=%{x}<br>Precision=%{y}\",\n",
    "        name=\"NN\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "print(\"done2\")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df7[(df7[\"detector\"] == \"ATLAS\") & (df7[\"model\"] == \"GB\")][\"recall\"].to_list()[0],\n",
    "        y=df7[(df7[\"detector\"] == \"ATLAS\") & (df7[\"model\"] == \"GB\")][\"precision\"].to_list()[0],\n",
    "        customdata=df7[(df7[\"detector\"] == \"ATLAS\") & (df7[\"model\"] == \"GB\")][\n",
    "            \"threshold\"\n",
    "        ].to_list()[0],\n",
    "        hovertemplate=\"Threshold=%{customdata}<br>Recall=%{x}<br>Precision=%{y}\",\n",
    "        name=\"GB\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df7[(df7[\"detector\"] == \"ATLAS\") & (df7[\"model\"] == \"RF\")][\"recall\"].to_list()[0],\n",
    "        y=df7[(df7[\"detector\"] == \"ATLAS\") & (df7[\"model\"] == \"RF\")][\"precision\"].to_list()[0],\n",
    "        customdata=df7[(df7[\"detector\"] == \"ATLAS\") & (df7[\"model\"] == \"RF\")][\n",
    "            \"threshold\"\n",
    "        ].to_list()[0],\n",
    "        hovertemplate=\"Threshold=%{customdata}<br>Recall=%{x}<br>Precision=%{y}\",\n",
    "        name=\"RF\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df7[(df7[\"detector\"] == \"CMS\") & (df7[\"model\"] == \"NN\")][\"recall\"].to_list()[0],\n",
    "        y=df7[(df7[\"detector\"] == \"CMS\") & (df7[\"model\"] == \"NN\")][\"precision\"].to_list()[0],\n",
    "        customdata=df7[(df7[\"detector\"] == \"CMS\") & (df7[\"model\"] == \"NN\")][\"threshold\"].to_list()[\n",
    "            0\n",
    "        ],\n",
    "        hovertemplate=\"Threshold=%{customdata}<br>Recall=%{x}<br>Precision=%{y}\",\n",
    "        marker_color=px.colors.qualitative.Plotly[0],\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df7[(df7[\"detector\"] == \"CMS\") & (df7[\"model\"] == \"GB\")][\"recall\"].to_list()[0],\n",
    "        y=df7[(df7[\"detector\"] == \"CMS\") & (df7[\"model\"] == \"GB\")][\"precision\"].to_list()[0],\n",
    "        customdata=df7[(df7[\"detector\"] == \"CMS\") & (df7[\"model\"] == \"GB\")][\"threshold\"].to_list()[\n",
    "            0\n",
    "        ],\n",
    "        hovertemplate=\"Threshold=%{customdata}<br>Recall=%{x}<br>Precision=%{y}\",\n",
    "        marker_color=px.colors.qualitative.Plotly[1],\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df7[(df7[\"detector\"] == \"CMS\") & (df7[\"model\"] == \"RF\")][\"recall\"].to_list()[0],\n",
    "        y=df7[(df7[\"detector\"] == \"CMS\") & (df7[\"model\"] == \"RF\")][\"precision\"].to_list()[0],\n",
    "        customdata=df7[(df7[\"detector\"] == \"CMS\") & (df7[\"model\"] == \"RF\")][\"threshold\"].to_list()[\n",
    "            0\n",
    "        ],\n",
    "        hovertemplate=\"Threshold=%{customdata}<br>Recall=%{x}<br>Precision=%{y}\",\n",
    "        marker_color=px.colors.qualitative.Plotly[2],\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "print(\"done3\")\n",
    "# fig.update_xaxes(title_text=\"Recall\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Precision\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Recall\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Precision\", row=2, col=1)\n",
    "fig.update_layout(\n",
    "    title=\"Precision-Recall curves\",\n",
    "    height=700,\n",
    "    width=600,\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0),\n",
    ")\n",
    "print(\"done4\")\n",
    "fig.write_image(\"pr_curves.pdf\")\n",
    "print(\"done5\")\n",
    "#fig.show()\n",
    "print(\"done6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    long_df,\n",
    "    x=\"detector\",\n",
    "    y=\"auc\",\n",
    "    color=\"model\",\n",
    "    barmode=\"group\",\n",
    "    facet_row=\"mSuu\",\n",
    "    facet_col=\"ECM\",\n",
    ")\n",
    "fig.update_yaxes(type=\"log\")\n",
    "fig.update_layout(\n",
    "    title=\"AUC for different detectors and ECMs\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecms = counts_df[\"ECM\"].unique()\n",
    "msuus = counts_df[\"mSuu\"].unique()\n",
    "detectors = counts_df[\"detector\"].unique()\n",
    "\n",
    "msuus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table(df, luminosity=3000):\n",
    "    # Extract unique values for ECM, mSuu, and detector to structure the table\n",
    "    ecms = df[\"ECM\"].unique()\n",
    "    msuus = df[\"mSuu\"].unique()\n",
    "    detectors = df[\"detector\"].unique()\n",
    "    df[\"cut\"] = df[\"cut\"].astype(float)\n",
    "\n",
    "    # Start the LaTeX table format\n",
    "    latex_str = \"\\\\begin{tabular}{|l|c|c|c|c|}\\n\\\\hline\\n\"\n",
    "    latex_str += \" & \\\\multicolumn{4}{c|}{Counts for cuts} \\\\\\\\ \\\\cline{2-5}\\n\"\n",
    "    latex_str += \"Event & 0.80 & 0.90 & 0.95 & 0.99 \\\\\\\\ \\\\hline\\n\"\n",
    "\n",
    "    # Loop over each combination of ECM, mSuu, and detector\n",
    "    for detector in detectors:\n",
    "        for ecm in ecms:\n",
    "            for msuu in msuus:\n",
    "                # Filter data for current combination\n",
    "                filtered_data = df[\n",
    "                    (df[\"ECM\"] == ecm) & (df[\"mSuu\"] == msuu) & (df[\"detector\"] == detector)\n",
    "                ]\n",
    "                if not filtered_data.empty:\n",
    "                    # For each cut, find the sum of BKG, SIG, and calculate S/B\n",
    "                    # for cut in [0.8, 0.90, 0.95, 0.99]:\n",
    "                    for cut in [0.90, 0.95, 0.97, 0.99]:\n",
    "                        bkg_sum = (\n",
    "                            filtered_data[\n",
    "                                (filtered_data[\"label\"] == \"BKG:sum\")\n",
    "                                & (filtered_data[\"cut\"] == cut)\n",
    "                            ][\"counts\"].values[0]\n",
    "                            * luminosity\n",
    "                        )\n",
    "                        sig_sum = (\n",
    "                            filtered_data[\n",
    "                                (filtered_data[\"label\"] == \"SIG:Suu\")\n",
    "                                & (filtered_data[\"cut\"] == cut)\n",
    "                            ][\"counts\"].values[0]\n",
    "                            * luminosity\n",
    "                        )\n",
    "                        sb_ratio = filtered_data[\n",
    "                            (filtered_data[\"label\"] == \"S/B\") & (filtered_data[\"cut\"] == cut)\n",
    "                        ][\"counts\"].values[0]\n",
    "                        # Add to LaTeX string\n",
    "                        latex_str += f\"{detector}, ECM={ecm}, mSuu={msuu} & {bkg_sum:.2e} & {sig_sum:.2e} & {sb_ratio:.2e} \\\\\\\\ \\\\hline\\n\"\n",
    "\n",
    "    # Close the LaTeX table format\n",
    "    latex_str += \"\\\\end{tabular}\"\n",
    "\n",
    "    return latex_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_table_1 = (\n",
    "    (\n",
    "        (counts_df[\"label\"] == \"BKG:sum\")\n",
    "        | (counts_df[\"label\"] == \"SIG:Suu\")\n",
    "        | (counts_df[\"label\"] == \"S/B\")\n",
    "    )\n",
    "    & (counts_df[\"ECM\"] == 13.6)\n",
    "    & counts_df[\"cut\"].isin([0.9, 0.95, 0.97, 0.99])\n",
    ")\n",
    "print(counts_df[mask_table_1].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_latex_table(counts_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table_with_multirow(df, luminosity=3000):\n",
    "    # Ensure 'cut' is of type float\n",
    "    df[\"cut\"] = df[\"cut\"].astype(float)\n",
    "\n",
    "    # Initialize the LaTeX table format with headers for each distinct category\n",
    "    latex_str = \"\\\\begin{tabular}{|l|l|l|c|c|c|c|}\\n\\\\hline\\n\"\n",
    "    latex_str += \"Detector & ECM & mSuu & \\\\multicolumn{4}{c|}{Counts for cuts} \\\\\\\\ \\\\cline{4-7}\\n\"\n",
    "    latex_str += \" & & & 0.80 & 0.90 & 0.95 & 0.99 \\\\\\\\ \\\\hline\\n\"\n",
    "\n",
    "    # Group by detector, ECM, mSuu to count occurrences\n",
    "    grouped = df.groupby([\"detector\", \"ECM\", \"mSuu\"])\n",
    "\n",
    "    for (detector, ecm, msuu), group in grouped:\n",
    "        num_rows = len(group[\"cut\"].unique())\n",
    "        first_row = True  # Indicator for the first row of each group\n",
    "\n",
    "        for cut in [0.90, 0.95, 0.97, 0.99]:\n",
    "            bkg_sum = sig_sum = sb_ratio = 0  # Default values\n",
    "            if cut in group[\"cut\"].values:\n",
    "                if ecm >= 13.6:\n",
    "                    luminosity = 1\n",
    "                elif ecm == 13.0:\n",
    "                    luminosity = 0.05 # Correct for luminosity\n",
    "                # Calculate values only if the cut exists in the group\n",
    "                bkg_sum = (\n",
    "                    group[(group[\"label\"] == \"BKG:sum\") & (group[\"cut\"] == cut)][\"counts\"].values[0]\n",
    "                    * luminosity\n",
    "                )\n",
    "                sig_sum = (\n",
    "                    group[(group[\"label\"] == \"SIG:Suu\") & (group[\"cut\"] == cut)][\"counts\"].values[0]\n",
    "                    * luminosity\n",
    "                )\n",
    "                sb_ratio = group[(group[\"label\"] == \"S/B\") & (group[\"cut\"] == cut)][\n",
    "                    \"counts\"\n",
    "                ].values[0]\n",
    "\n",
    "            if first_row:\n",
    "                # Use \\multirow for the first row in each group\n",
    "                latex_str += f\"\\\\multirow{{{num_rows}}}{{*}}{{{detector}}} & \\\\multirow{{{num_rows}}}{{*}}{{{ecm}}} & \\\\multirow{{{num_rows}}}{{*}}{{{msuu}}} & {cut} & {bkg_sum:.2e} & {sig_sum:.2e} & {sb_ratio:.2e} \\\\\\\\ \\\\cline{4-7}\\n\"\n",
    "                first_row = False\n",
    "            else:\n",
    "                # Only include cut-specific data in subsequent rows\n",
    "                latex_str += f\" & & & {cut} & {bkg_sum:.3} & {sig_sum:.3} & {sb_ratio:.3} \\\\\\\\ \\\\cline{4-7}\\n\"\n",
    "\n",
    "    # Close the LaTeX table format\n",
    "    latex_str += \"\\\\end{tabular}\"\n",
    "\n",
    "    return latex_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_latex_table_with_multirow(counts_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table_with_multirow_corrected(df, luminosity=3000):\n",
    "    # Convert 'cut' to float to ensure proper sorting and comparison\n",
    "    df[\"cut\"] = df[\"cut\"].astype(float)\n",
    "\n",
    "    # Initialize the LaTeX table format with headers\n",
    "    latex_str = \"\\\\begin{tabular}{|l|l|l|c|c|c|c|}\\n\\\\hline\\n\"\n",
    "    latex_str += (\n",
    "        \"Detector & ECM & mSuu & \\\\multicolumn{4}{c|}{Event Counts for cuts} \\\\\\\\ \\\\cline{4-7}\\n\"\n",
    "    )\n",
    "    latex_str += \" & & & cut & Background & Signal & S/B \\\\\\\\ \\\\hline\\n\"\n",
    "\n",
    "    # Calculate the number of rows needed for the multirow command dynamically\n",
    "    detector_group = df.groupby([\"detector\"])\n",
    "    for detector, detector_df in detector_group:\n",
    "        detector_rows = len(detector_df.groupby([\"ECM\", \"mSuu\"]).size())\n",
    "        ecm_group = detector_df.groupby([\"ECM\"])\n",
    "        for ecm, ecm_df in ecm_group:\n",
    "            ecm_rows = len(ecm_df.groupby([\"mSuu\"]).size())\n",
    "            msuu_group = ecm_df.groupby([\"mSuu\"])\n",
    "            for msuu, msuu_df in msuu_group:\n",
    "                msuu_rows = len(msuu_df[\"cut\"].unique())\n",
    "                first_row = True\n",
    "                for _, row in msuu_df.iterrows():\n",
    "                    cut = row[\"cut\"]\n",
    "                    bkg_sum = row[\"counts\"] if row[\"label\"] == \"BKG:sum\" else 0\n",
    "                    sig_sum = row[\"counts\"] if row[\"label\"] == \"SIG:Suu\" else 0\n",
    "                    sb_ratio = row[\"counts\"] if row[\"label\"] == \"S/B\" else 0\n",
    "                    if first_row:\n",
    "                        latex_str += f\"\\\\multirow{{{detector_rows}}}{{*}}{{{detector}}} & \\\\multirow{{{ecm_rows}}}{{*}}{{{ecm}}} & \\\\multirow{{{msuu_rows}}}{{*}}{{{msuu}}} & {cut} & {bkg_sum:.2e} & {sig_sum:.2e} & {sb_ratio:.2e} \\\\\\\\\\n\"\n",
    "                        first_row = False\n",
    "                    else:\n",
    "                        latex_str += (\n",
    "                            f\" & & & {cut} & {bkg_sum:.2e} & {sig_sum:.2e} & {sb_ratio:.2e} \\\\\\\\\\n\"\n",
    "                        )\n",
    "                detector_rows -= msuu_rows\n",
    "                if detector_rows > 0:  # If there are more rows to cover for this detector\n",
    "                    latex_str += \"\\\\cline{2-7}\\n\"\n",
    "            if ecm_rows > msuu_rows:  # Adjust for next ECM if necessary\n",
    "                latex_str += \"\\\\cline{3-7}\\n\"\n",
    "\n",
    "    latex_str += \"\\\\hline\\n\\\\end{tabular}\"\n",
    "\n",
    "    return latex_str\n",
    "\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "latex_table_corrected = generate_latex_table_with_multirow_corrected(counts_df)\n",
    "print(latex_table_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = counts_df[\n",
    "    (counts_df[\"ECM\"] == 13.6) & (counts_df[\"mSuu\"] == 8.5) & (counts_df[\"detector\"] == \"CMS\")\n",
    "][[\"label\", \"cut\", \"counts\"]].reset_index(drop=True)\n",
    "df_0.loc[df_0[\"label\"] != \"S/B\", \"counts\"]  # *= 150 / 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0[df_0.label == \"SIG:Suu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0[df_0.label == \"S/B\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diquark.constants import DATA_KEYS\n",
    "\n",
    "df_pivot = (\n",
    "    df_0.pivot(index=\"label\", columns=\"cut\", values=\"counts\")\n",
    "    .loc[DATA_KEYS + [\"BKG:sum\", \"S/B\"], [0.2, 0.5, 0.9, 0.95, 0.97, 0.99]]\n",
    "    .reset_index()\n",
    ")\n",
    "df_pivot.to_csv(\"counts_CMS_136_70.csv\", index=False)\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
